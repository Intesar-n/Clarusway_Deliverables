{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfUdHCfe1b6v"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "heading_collapsed": true,
    "id": "CvFxPmf41b6y"
   },
   "source": [
    "# WELCOME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "id": "WZUMKNQY1b6y"
   },
   "source": [
    "In this project, you must apply EDA processes for the development of predictive models. Handling outliers, domain knowledge and feature engineering will be challenges.\n",
    "\n",
    "Also, this project aims to improve your ability to implement algorithms for Multi-Class Classification. Thus, you will have the opportunity to implement many algorithms commonly used for Multi-Class Classification problems.\n",
    "\n",
    "Before diving into the project, please take a look at the determines and tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "heading_collapsed": true,
    "id": "laCRtJs51b6z"
   },
   "source": [
    "# Determines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "id": "iixh9Bej1b6z"
   },
   "source": [
    "The 2012 US Army Anthropometric Survey (ANSUR II) was executed by the Natick Soldier Research, Development and Engineering Center (NSRDEC) from October 2010 to April 2012 and is comprised of personnel representing the total US Army force to include the US Army Active Duty, Reserves, and National Guard. In addition to the anthropometric and demographic data described below, the ANSUR II database also consists of 3D whole body, foot, and head scans of Soldier participants. These 3D data are not publicly available out of respect for the privacy of ANSUR II participants. The data from this survey are used for a wide range of equipment design, sizing, and tariffing applications within the military and has many potential commercial, industrial, and academic applications.\n",
    "\n",
    "The ANSUR II working databases contain 93 anthropometric measurements which were directly measured, and 15 demographic/administrative variables explained below. The ANSUR II Male working database contains a total sample of 4,082 subjects. The ANSUR II Female working database contains a total sample of 1,986 subjects.\n",
    "\n",
    "\n",
    "DATA DICT:\n",
    "https://data.world/datamil/ansur-ii-data-dictionary/workspace/file?filename=ANSUR+II+Databases+Overview.pdf\n",
    "\n",
    "---\n",
    "\n",
    "To achieve high prediction success, you must understand the data well and develop different approaches that can affect the dependent variable.\n",
    "\n",
    "Firstly, try to understand the dataset column by column using pandas module. Do research within the scope of domain (body scales, and race characteristics) knowledge on the internet to get to know the data set in the fastest way. \n",
    "\n",
    "You will implement ***Logistic Regression, Support Vector Machine, XGBoost, Random Forest*** algorithms. Also, evaluate the success of your models with appropriate performance metrics.\n",
    "\n",
    "At the end of the project, choose the most successful model and try to enhance the scores with ***SMOTE*** make it ready to deploy. Furthermore, use ***SHAP*** to explain how the best model you choose works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "heading_collapsed": true,
    "id": "P2UckCvP1b60"
   },
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "id": "gCVDEsGB1b60"
   },
   "source": [
    "#### 1. Exploratory Data Analysis (EDA)\n",
    "- Import Libraries, Load Dataset, Exploring Data\n",
    "\n",
    "    *i. Import Libraries*\n",
    "    \n",
    "    *ii. Ingest Data *\n",
    "    \n",
    "    *iii. Explore Data*\n",
    "    \n",
    "    *iv. Outlier Detection*\n",
    "    \n",
    "    *v.  Drop unnecessary features*\n",
    "\n",
    "#### 2. Data Preprocessing\n",
    "- Scale (if needed)\n",
    "- Separete the data frame for evaluation purposes\n",
    "\n",
    "#### 3. Multi-class Classification\n",
    "- Import libraries\n",
    "- Implement SVM Classifer\n",
    "- Implement Decision Tree Classifier\n",
    "- Implement Random Forest Classifer\n",
    "- Implement XGBoost Classifer\n",
    "- Compare The Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Y5-Kay1Eqvdj"
   },
   "source": [
    "# EDA\n",
    "- Drop unnecessary colums\n",
    "- Drop DODRace class if value count below 500 (we assume that our data model can't learn if it is below 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "K7UZHtvu1b62"
   },
   "source": [
    "## Import Libraries\n",
    "Besides Numpy and Pandas, you need to import the necessary modules for data visualization, data preprocessing, Model building and tuning.\n",
    "\n",
    "*Note: Check out the course materials.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OqnRjwHB1b64"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact\n",
    "\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    make_scorer,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    average_precision_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "C5lJeTBu1b65"
   },
   "source": [
    "## Ingest Data from links below and make a dataframe\n",
    "- Soldiers Male : https://query.data.world/s/h3pbhckz5ck4rc7qmt2wlknlnn7esr\n",
    "- Soldiers Female : https://query.data.world/s/sq27zz4hawg32yfxksqwijxmpwmynq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "hidden": true,
    "id": "tG5BsWraqX_y",
    "outputId": "a6e730fa-6848-4cfc-becb-284fc8cc99e5"
   },
   "outputs": [],
   "source": [
    "# Ingesting the data using 2 variables then concating them in a single variable\n",
    "df_male = pd.read_csv('https://query.data.world/s/h3pbhckz5ck4rc7qmt2wlknlnn7esr',encoding='latin-1')\n",
    "df_female= pd.read_csv('https://query.data.world/s/sq27zz4hawg32yfxksqwijxmpwmynq')\n",
    "merged_df = pd.concat([df_female,df_male])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "TMjCTEG51b67"
   },
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see here that we have 108 features (Target excluded)\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# As we can see the mean and std are really close to each other which indicates having outliers\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We notice that we have null values\n",
    "merged_df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No duplicates (I mean, obviously? (fool me once, shame on you; fool me twice, shame on me, fool me 108 times??))\n",
    "merged_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "hidden": true,
    "id": "SnlGRPWbrNAj",
    "outputId": "29ed8227-1450-4213-e9d1-a2953167d415",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_df\n",
    "# Dropped because it isn't related to race:\n",
    "#-------------------------------------------\n",
    "# Age (was taken during collecting data (limited to the range of accepting soldiers and isn't reasonable to use))\n",
    "\n",
    "# Date (shows the date the data was collected so it has no influence on the race in any way)\n",
    "\n",
    "# SubjectID (We don't need to know the individuals specifically) \n",
    "\n",
    "# WritingPreference (Could vary based on multiple things aside the race)\n",
    "\n",
    "# Weightlbs (Weight in Kgs is preffered since they are the units used in the Metric System and it was self reported so they \n",
    "# aren't 100% reliable)\n",
    "\n",
    "# Heightin ( Since it is self reported so it isn't reliable and we can use the stature instead as it represents the \n",
    "# natural height of a person measuring the bones that contribute to a person's height)\n",
    "\n",
    "# Branch, Component, Installation, PrimaryMOS (The placement of the soldiers does not vary based on race) \n",
    "\n",
    "# SubjectNumericRace (It has all the races a single observation has so it isn't helpful if we are trying to know the \n",
    "\n",
    "# differences in each race and since it also includes the DODRace it will cause data leakage)\n",
    "\n",
    "# If these reasons aren't convincing, let's call them my assumptions :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's take a look on the features with null values \n",
    "# We can see that both SubjectId and subjectid are going to be dropped anyway, but for the sake of explanation, the reason we \n",
    "# see these null values is because they are treated as different columns from each df (female and male)\n",
    "# So now we are interested in the ethnicity since it has 4647 null values and a reminder the total number of observations is 6068\n",
    "# Since the number of null values in the Ethnicity is large (More than 70%) we are saying goodbye to Ethnicity\n",
    "drop_list = []\n",
    "for col in merged_df:\n",
    "    if merged_df[col].isnull().sum() > 0:\n",
    "        print(f\"{col} = {merged_df[col].isnull().sum()}\")\n",
    "        drop_list.append(col)\n",
    "\n",
    "\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now dropping all the features we found unrelated and with so much null values:  \n",
    "print(f\"The shape of DataFrame BEFORE dropping null/unnecessary features: rows are {merged_df.shape[0]} and columns are {merged_df.shape[1]}\")\n",
    "merged_df.drop(columns=[\"Age\", \"Date\", \"subjectid\", \"SubjectId\" ,\"WritingPreference\", \"Weightlbs\", \"Branch\",\"Component\",\"Ethnicity\",\"Installation\", \"SubjectNumericRace\", \"PrimaryMOS\", \"Heightin\"\n",
    "], inplace=True)\n",
    "print(f\"The shape of DataFrame AFTER dropping null/unnecessary features : rows are {merged_df.shape[0]} and columns are {merged_df.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are asked to remove DODRace classes with less than 500 observations assuming the model can't learn from them\n",
    "# Let's take a look on those classes first:\n",
    "\n",
    "\"\"\"\"\"\n",
    "1 = White \n",
    "2 = Black \n",
    "3 = Hispanic \n",
    "4 = Asian \n",
    "5 = Native American \n",
    "6 = Pacific Islander\n",
    "8 = Other\n",
    "\"\"\"\"\"\n",
    "merged_df.DODRace.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cool, let's see clearly?\n",
    "print(merged_df[\"DODRace\"].value_counts())\n",
    "merged_df[\"DODRace\"].value_counts().plot(kind=\"bar\"\n",
    "                                         , figsize=(10, 10))\n",
    "plt.xlabel(\"Races\");\n",
    "plt.ylabel(\"Number of Soldiers\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Even MORE clearly !\n",
    "\n",
    "1 = White \n",
    "2 = Black \n",
    "3 = Hispanic \n",
    "4 = Asian\n",
    "5 = Native American\n",
    "6 = Pacific Islander \n",
    "8 = Other\n",
    "\"\"\"\"\"\n",
    "print(merged_df[\"DODRace\"].value_counts())\n",
    "merged_df[\"DODRace\"].value_counts().plot(kind=\"pie\" , autopct=\"%1.1f%%\", figsize=(5, 5))\n",
    "plt.ylabel(\"\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have classes (4, 5, 6, and 8) having observations less than 500 then they must be dropped\n",
    "\n",
    "drop_DODRace = merged_df.DODRace.value_counts()[merged_df.DODRace.value_counts() <= 500].index\n",
    "drop_DODRace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of DataFrame BEFORE dropping classes with less than 500 observations : rows are {merged_df.shape[0]} and columns are {merged_df.shape[1]}\")\n",
    "for i in drop_DODRace:\n",
    "    drop_index = merged_df[merged_df['DODRace'] == i].index\n",
    "    merged_df.drop(index = drop_index, inplace=True)\n",
    "\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"The shape of DataFrame AFTER dropping classes with less than 500 observations : rows are {merged_df.shape[0]} and columns are {merged_df.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_df.DODRace.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "1 = White \n",
    "2 = Black \n",
    "3 = Hispanic\n",
    "\n",
    "\"\"\"\"\"\n",
    "print(merged_df[\"DODRace\"].value_counts())\n",
    "merged_df[\"DODRace\"].value_counts().plot(kind=\"bar\"\n",
    "                                         , figsize=(5, 5))\n",
    "plt.xlabel(\"Races\");\n",
    "plt.ylabel(\"Number of Soldiers\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(merged_df[\"DODRace\"].value_counts())\n",
    "merged_df[\"DODRace\"].value_counts().plot(kind=\"pie\" , autopct=\"%1.1f%%\", figsize=(5, 5))\n",
    "plt.ylabel(\"\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now let's do some mapping! \n",
    "\n",
    "# As you may have noticed we have the Gender as [Male, Female], but we like numbers! \n",
    "merged_df[\"Gender\"] =merged_df[\"Gender\"].map({\"Female\":0,\"Male\":1})\n",
    "merged_df[\"Gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now for the SubjectsBirthLocation, let's see what do we have as values\n",
    "# We notice that we have the states mentioned separately compared to countries, which doesn't make since\n",
    "# because they all represent one country\n",
    "#------\n",
    "# To solve this issue we can go mutliple ways:\n",
    "# either divide the states based on their part of the US (West, East, North, and South)\n",
    "# or divide the countries and states based on continents (Asia, Europe..etc)\n",
    "# Fnailly my chosen way is to divide based on whether a soldier is from the US (Whichever state) or from a foreign country\n",
    "\n",
    "locations =  merged_df['SubjectsBirthLocation'].unique()\n",
    "result = \", \".join(locations)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason I'm going with the last solution is that most of the observations are from the US \n",
    "# (obvious right? since it's the US soldiers data) \n",
    "merged_df['SubjectsBirthLocation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida',\n",
    "    'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine',\n",
    "    'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska',\n",
    "    'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',\n",
    "    'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas',\n",
    "    'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming', 'American Samoa',\n",
    "    'District of Columbia', 'Guam', 'Northern Mariana Islands', 'Puerto Rico', 'US Virgin Islands'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['SubjectsBirthLocation'] = merged_df['SubjectsBirthLocation'].apply(lambda x: 1 if any(state.lower() in x.lower() for state in states) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df['SubjectsBirthLocation'].value_counts().unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "CS5-GZy0sl4s"
   },
   "source": [
    "# DATA Preprocessing\n",
    "- In this step we divide our data to X(Features) and y(Target) then ,\n",
    "- To train and evaluation purposes we create train and test sets,\n",
    "- Lastly, scale our data if features not in same scale. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "fr2wgpvk1b7B"
   },
   "outputs": [],
   "source": [
    "X = merged_df.drop(columns=[\"DODRace\"])\n",
    "y = merged_df.DODRace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=101, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train independent variables shape : \", X_train.shape)\n",
    "print(\"Train dependent variable shape   : \", y_train.shape)\n",
    "print(\"Test independent variables shape  : \", X_test.shape)\n",
    "print(\"Test dependent variable shape    : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "zfi_NOw0s2fM"
   },
   "source": [
    "# Modelling\n",
    "- Fit the model with train dataset\n",
    "- Get predict from vanilla model on both train and test sets to examine if there is over/underfitting   \n",
    "- Apply GridseachCV for both hyperparemeter tuning and sanity test of our model.\n",
    "- Use hyperparameters that you find from gridsearch and make final prediction and evaluate the result according to chosen metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "N1cviBuh1b7C"
   },
   "source": [
    "## 1. Logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "0rSJ5hxp1b7C"
   },
   "source": [
    "### Vanilla Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbKDDck012BS"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "Logistic_Model = LogisticRegression()\n",
    "Standard_Scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "Logistick_pip = Pipeline([('scaler',StandardScaler()),('Logistic_Model',LogisticRegression())])\n",
    "Logistick_pip.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =Logistick_pip.predict(X_test)\n",
    "y_train_pred = Logistick_pip.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    " -----------------    Train Results      -----------------\n",
    "{classification_report(y_train, y_train_pred)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\n",
    "{classification_report(y_test, y_pred)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_score, recall_score,  f1_score\n",
    "\n",
    "\n",
    "f1_S = make_scorer(f1_score, average = \"weighted\")\n",
    "precision_S = make_scorer(precision_score, average = \"weighted\")\n",
    "recall_S = make_scorer(recall_score, average = \"weighted\")\n",
    "\n",
    "\n",
    "scoring = {\"f1r\":f1_S,\n",
    "           \"precision\":precision_S,\n",
    "           \"recall\":recall_S} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [(\"scaler\", StandardScaler()), (\"logistic\", LogisticRegression())]\n",
    "model = Pipeline(steps=operations)\n",
    "\n",
    "scores = cross_validate(model, X_train, y_train, scoring = scoring, cv = 10, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores, index = range(1,11))\n",
    "df_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "lPelWxsU1b7C"
   },
   "source": [
    "### Logistic Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [(\"scaler\", StandardScaler()), (\"logistic_model\", LogisticRegression(max_iter=5000))]\n",
    "GridModel = Pipeline(steps=operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNZyqeNY15nP"
   },
   "outputs": [],
   "source": [
    "param_grid = { \"logistic_model__class_weight\" : [\"balanced\"],               \n",
    "               'logistic_model__solver' : ['saga','lbfgs','liblinear'],\n",
    "              'logistic_model__penalty': [\"l1\",\"l2\"],\n",
    "               'logistic_model__C' :[0.01, 0.1, 0.5 ,1]\n",
    "             }\n",
    "f1_Hispanic =  make_scorer(f1_score, average=None, labels=[3])# Class 3 represent the Hispanic which is the worst scoring for our model and we need to foucs on it \n",
    "# Average can be (weighted, macro) if wanna foucse on one of these and so on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_Logistick_pipe = GridSearchCV(GridModel, param_grid = param_grid,scoring=f1_Hispanic, cv=5, return_train_score=True,n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_Logistick_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best hyperparameters: \n",
    "grid_Logistick_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid =grid_Logistick_pipe.predict(X_test)\n",
    "y_train_pred_grid = grid_Logistick_pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'''\n",
    "----------------------------- Train Results -----------------------------\\n\n",
    "{classification_report(y_train, y_train_pred_grid)}\n",
    "                        \n",
    "----------------------------- Test Results -----------------------------\\n\n",
    "{classification_report(y_test, y_pred_grid)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(5,5)):\n",
    "    y_score = clf.decision_function(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "plot_multiclass_roc(grid_Logistick_pipe, X_test, y_test, n_classes=3, figsize=(16, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikitplot.metrics import plot_roc, plot_precision_recall\n",
    "\n",
    "y_pred_proba = grid_Logistick_pipe.predict_proba(X_test)\n",
    "\n",
    "plot_precision_recall(y_test, y_pred_proba)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "GM0PL5eZ1b7E"
   },
   "source": [
    "## 2. SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "P3j_Xk1L1b7E"
   },
   "source": [
    "### Vanilla SVC model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pro8T6CM19vX"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import PrecisionRecallDisplay, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_SVM = [(\"scaler\", StandardScaler()), (\"SVC\", SVC(class_weight=\"balanced\",probability=True))]\n",
    "SVC_pipeline = Pipeline(steps=operations_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_svm = SVM_pipe.predict(X_test)\n",
    "y_train_pred_SVM = SVM_pipe.predict(X_train)\n",
    "print(f'''\n",
    " -----------------    Train Results      -----------------\\n\n",
    "{classification_report(y_train, y_train_pred_SVM)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\\n\n",
    "{classification_report(y_test, y_pred_svm)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dictionary_bar(dictionary):\n",
    " keys = dictionary.keys()\n",
    " values = dictionary.values()\n",
    "\n",
    " plt.bar(keys, values)\n",
    " plt.xlabel(\"Keys\")\n",
    " plt.ylabel(\"Values\")\n",
    " plt.title(\"Dictionary Bar Chart\")\n",
    "\n",
    " plt.show()\n",
    "\n",
    "plot_dictionary_bar(classification_report(y_test, y_pred_svm,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(SVM_pipe,\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        scoring=scoring,\n",
    "                        cv = 5,\n",
    "                        return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores, index = range(1, 6))\n",
    "df_scores.mean()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "28y9nWxG1b7E"
   },
   "source": [
    "###  SVC Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dFocgCo1-0Z"
   },
   "outputs": [],
   "source": [
    "SVM_pipe_grid = Pipeline(steps=operations_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'SVC__C': [0.01 ,0.1, 0.5,1],\n",
    "              'SVC__gamma': [\"scale\", \"auto\", 0.01],\n",
    "              'SVC__kernel': ['rbf', 'linear','poly'],             \n",
    "              'SVC__class_weight': [\"balanced\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_grid = GridSearchCV(SVM_pipe_grid, param_grid, verbose=3, scoring=f1_Hispanic, refit=True,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_grid = svm_model_grid.predict(X_test)\n",
    "y_train_pred_SVM_grid = svm_model_grid.predict(X_train)\n",
    "print(f'''\n",
    " -----------------    Train Results      -----------------\\n\n",
    "{classification_report(y_train, y_train_pred_SVM_grid)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\\n\n",
    "{classification_report(y_test, y_pred_svm_grid)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = svm_model_grid.predict_proba(X_test)\n",
    "\n",
    "plot_precision_recall(y_test, y_pred_proba)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "bDX_iLIls74C"
   },
   "source": [
    "## 3. RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "qaTzrT6P1b7G"
   },
   "source": [
    "### Vanilla RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvtqL0Qg2CKf"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We notice the model is overfitting\n",
    "\n",
    "y_pred_RF = RF_model.predict(X_test)\n",
    "y_train_pred_RF = RF_model.predict(X_train)\n",
    "print(f'''\n",
    " -----------------    Train Results      -----------------\n",
    "{classification_report(y_train, y_train_pred_RF)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\n",
    "{classification_report(y_test, y_pred_RF)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "MkLAZ_M41b7G"
   },
   "source": [
    "### RF Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpmPr3202EbD"
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[400,500],\n",
    "             'criterion': [\"gini\",\"entropy\"],\n",
    "             'max_depth':[2,3,10,14],\n",
    "             'min_samples_split':[18,20,22],\n",
    "             'class_weight': ['balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_model = GridSearchCV(RF_model, param_grid, verbose=3, scoring=f1_Hispanic, refit=True,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF_grid = rf_grid_model.predict(X_test)\n",
    "y_train_pred_RF_grid = rf_grid_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    " -----------------    Train Results      -----------------\n",
    "{classification_report(y_train, y_train_pred_RF_grid)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\n",
    "{classification_report(y_test, y_pred_RF_grid)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf_grid_model.predict_proba(X_test)\n",
    "\n",
    "plot_precision_recall(y_test, y_pred_proba)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "PvcPc4V81b7H"
   },
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "MuxxUFoW1b7H"
   },
   "source": [
    "### Vanilla XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nfi1aa152HbR"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_pipe =Pipeline([('Scaler',StandardScaler()),('XGB',XGBClassifier())]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_xgb = y_train.map({1: 0, 2:1,3:2})\n",
    "y_test_xgb = y_test.map({1: 0, 2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_pipe.fit(X_train,y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB= xgboost_pipe.predict(X_test)\n",
    "y_train_pred_XGB = xgboost_pipe.predict(X_train)\n",
    "\n",
    "print(f'''\n",
    " -----------------    Train Results      -----------------\n",
    "{classification_report(y_train_xgb, y_train_pred_XGB)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\n",
    "{classification_report(y_test_xgb, y_pred_XGB)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight=\"balanced\", y=y_train_xgb\n",
    ")\n",
    "classes_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"weights\": classes_weights, \"label\": y_train_xgb}\n",
    "\n",
    "comp = pd.DataFrame(my_dict)\n",
    "\n",
    "comp.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.groupby(\"label\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    xgboost_pipe,\n",
    "    X_train,\n",
    "    y_train_xgb,\n",
    "    scoring=scoring,\n",
    "    cv=5,\n",
    "    n_jobs=1, \n",
    "    return_train_score=True,\n",
    "    fit_params={\"XGB__sample_weight\": classes_weights},\n",
    ")\n",
    "df_scores = pd.DataFrame(scores, index=range(1, 6))\n",
    "df_scores.mean()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "p3gH5QvE1b7I"
   },
   "source": [
    "### XGBoost Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72E3Cmnm2KOE"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"XGB__n_estimators\": [100, 300],\n",
    "    \"XGB__max_depth\": [1,2,5],\n",
    "    \"XGB__learning_rate\": [0.03, 0.05],\n",
    "    \"XGB__subsample\": [0.3, 0.8,1],\n",
    "    \"XGB__colsample_bytree\": [0.5,0.8, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_pipe_grid =Pipeline([('Scaler',StandardScaler()),('XGB',XGBClassifier())]) \n",
    "xGBoost_Grid = GridSearchCV(\n",
    "    xgboost_pipe_grid,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(recall_score, average=None, labels=[2]),\n",
    "    cv=5,\n",
    "    n_jobs=1,\n",
    "    return_train_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xGBoost_Grid.fit(X_train, y_train_xgb, XGB__sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xGBoost_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB= xGBoost_Grid.predict(X_test)\n",
    "y_train_pred_XGB = xGBoost_Grid.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'''\n",
    " -----------------    Train Results      -----------------\n",
    "{classification_report(y_train_xgb, y_train_pred_XGB)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\n",
    "{classification_report(y_test_xgb, y_pred_XGB)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tuned Logistic regression model has the best results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "DbXAmOPVDatl"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WvWpInu21b7L"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "xg2k1ScZ1b7L"
   },
   "source": [
    "# SMOTE\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "9Rqk02x61b7L"
   },
   "source": [
    "##  Smote implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XTN4iO7i1b7L"
   },
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Cv5155AN1b7L"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import  Pipeline as Imb_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1FSKgtbaylV"
   },
   "outputs": [],
   "source": [
    "over = SMOTE()\n",
    "X_train_over, y_train_over = over.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "Shape of X_train is  :      {}\n",
    "Shape of X_train over is  : {}\n",
    "Shape of y_train is :       {}\n",
    "Shape of y_train over is :  {}\n",
    "--------------each class------------------\n",
    "{}\n",
    "'''.format(X_train.shape,X_train_over.shape,y_train.shape,y_train_over.shape,y_train_over.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under = RandomUnderSampler()\n",
    "X_train_under, y_train_under = under.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "Shape of X_train is  :       {}\n",
    "Shape of X_train under is  : {}\n",
    "Shape of y_train is :        {}\n",
    "Shape of y_train under is :  {}\n",
    "--------------each class------------------\n",
    "{}\n",
    "\n",
    "'''.format(X_train.shape,X_train_under.shape,y_train.shape,y_train_under.shape, y_train_under.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy={3: 1000})\n",
    "under = RandomUnderSampler(sampling_strategy={1: 2000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled_over, y_resampled_over = over.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"o\", over), (\"u\", under)]\n",
    "\n",
    "\n",
    "pipeline = Imb_pip(steps=steps)\n",
    "\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "\n",
    "--------Y before-------- \\n\n",
    "{}\n",
    "\\n\\n--------Smote smapling--------\\n\n",
    "{}\n",
    "'''.format(y_train.value_counts(),y_resampled.value_counts()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "1hBIqmFL1b7O"
   },
   "source": [
    "## Logistic Regression Over/ Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12AItu1M2ds0"
   },
   "outputs": [],
   "source": [
    "operations = [\n",
    "    (\"o\", over),\n",
    "    (\"u\", under),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logistic_reg\", LogisticRegression(max_iter=10000)),\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLsqCpGn7jNM"
   },
   "outputs": [],
   "source": [
    "smote_pipeline = Imb_pip(steps=operations)\n",
    "smote_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote= smote_pipeline.predict(X_test)\n",
    "y_train_pred_smote = smote_pipeline.predict(X_train)\n",
    "\n",
    "print(f'''\n",
    " -----------------    Train Results      -----------------\n",
    "{classification_report(y_train, y_train_pred_smote)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\n",
    "{classification_report(y_test, y_pred_smote)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Imb_pip(steps=operations)\n",
    "\n",
    "scores = cross_validate(\n",
    "    model, X_train, y_train, scoring=scoring, cv=10, n_jobs=1, return_train_score=True\n",
    ")\n",
    "df_scores = pd.DataFrame(scores, index=range(1, 11))\n",
    "df_scores.mean()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \"logistic_reg__class_weight\" : [\"balanced\", None],\n",
    "               'logistic_reg__penalty': [\"l1\",\"l2\"],\n",
    "               'logistic_reg__solver' : ['saga','lbfgs','liblinear'],\n",
    "               'logistic_reg__C' :[0.001,0.01, 0.1, 1, 5, 10, 15, 20, 25]\n",
    "             }\n",
    "f1_Hispanic =  make_scorer(f1_score, average=None, labels=[3])# Class 3 represent the Hispanic which is the worst scoring for our model and we need to foucs on it \n",
    "# Average can be (weighted, macro) if wanna foucse on one of these and so on \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_Logistick_smote_pipe = GridSearchCV(smote_pipeline, param_grid = param_grid,scoring=f1_Hispanic, cv=5, return_train_score=True,n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_Logistick_smote_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_Logistick_smote_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote= grid_Logistick_smote_pipe.predict(X_test)\n",
    "y_train_pred_smote = grid_Logistick_smote_pipe.predict(X_train)\n",
    "print(f'''\n",
    " -----------------    Train Results      -----------------\n",
    "{classification_report(y_train, y_train_pred_smote)}\n",
    "                        \n",
    "-----------------    Test Results      -----------------\n",
    "{classification_report(y_test, y_pred_smote)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9A1B65L7jwp"
   },
   "source": [
    "## Other Evaluation Metrics for Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "T1pPLjpA1b7P"
   },
   "source": [
    "- Evaluation metrics \n",
    "https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Me3OZtQF1b7P",
    "outputId": "6280fddb-b392-40c1-87d3-57d242ce2528"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef?\n",
    "matthews_corrcoef(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "P74oLhzK1b7P",
    "outputId": "350b8e9d-dd72-4566-8b11-10526699cd94"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score?\n",
    "cohen_kappa_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "9hxUcvZG1b7J"
   },
   "source": [
    "# Before the Deployment \n",
    "- Choose the model that works best based on your chosen metric\n",
    "- For final step, fit the best model with whole dataset to get better performance.\n",
    "- And your model ready to deploy, dump your model and scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UOn_G0n2N2Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "g8_x-BiN1b7Q"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "K7UZHtvu1b62",
    "C5lJeTBu1b65",
    "TMjCTEG51b67",
    "CS5-GZy0sl4s",
    "zfi_NOw0s2fM",
    "p3gH5QvE1b7I",
    "xg2k1ScZ1b7L",
    "1hBIqmFL1b7O",
    "j9A1B65L7jwp",
    "9hxUcvZG1b7J"
   ],
   "provenance": []
  },
  "hide_input": false,
  "interpreter": {
   "hash": "e4e90950cb561445fc7289d5187c528b28750a487d008a70b474c773afaf79b7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "338.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 527,
   "position": {
    "height": "40px",
    "left": "1034px",
    "right": "20px",
    "top": "185px",
    "width": "661px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
